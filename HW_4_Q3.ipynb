{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Import Libraries**"
      ],
      "metadata": {
        "id": "LYDEpvfh7aKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D,Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "import keras.applications\n",
        "from keras.applications.efficientnet import preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "4oWJrs31oG1q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Required Functions**"
      ],
      "metadata": {
        "id": "yxd37oybJuJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(addr):\n",
        "  # addr (input) is directory of the image\n",
        "  img = keras.utils.load_img(addr, target_size=(224, 224))\n",
        "  # Turn to array of shape (224, 224, 3)\n",
        "  img = keras.utils.img_to_array(img)\n",
        "  # Expand array into (1, 224, 224, 3)\n",
        "  img = np.expand_dims(img, 0)\n",
        "  return img"
      ],
      "metadata": {
        "id": "_c5iiGGmAOXN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_model(x_train,y_train,x_valid,y_valid,num_epochs):  \n",
        "  effnetB0=Sequential()\n",
        "  effnetB0.add(keras.applications.EfficientNetB0(weights='imagenet', include_top=True))\n",
        "  effnetB0.add(Dense(2,activation='softmax'))\n",
        "  optimizer = Adam(lr=0.0001)\n",
        "\n",
        "  early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
        "\n",
        "  rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience= 5, factor= 0.5, min_lr= 1e-6, verbose=1)\n",
        "  effnetB0.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics=['accuracy'])\n",
        "  model_history = effnetB0.fit(x_train, y_train,validation_data = (x_valid, y_valid), callbacks = [early_stop, rlrop],verbose = 1, epochs = num_epochs)"
      ],
      "metadata": {
        "id": "1hXe-0lgk6De"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(img,model,condition_check):\n",
        "  pred = model.predict(img)\n",
        "  if np.max(pred)*100<20 and condition_check:\n",
        "    print('The Network could not classify the object.') \n",
        "    print('Maybe the object does not exist in the list of the labels!')\n",
        "  else:\n",
        "    for i in range(3):\n",
        "      name = decode_predictions(pred)[0][i][1]\n",
        "      prob = decode_predictions(pred)[0][i][2]*100\n",
        "      print(f'Detected Object : {name}, Probability: {np.round(prob, 2)}%')"
      ],
      "metadata": {
        "id": "3mVYPeAxl8YX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Import_data(dir1,dir2):\n",
        "  # Label of Computers = 1 , Label of Motorbikes = 0 \n",
        "  x = []\n",
        "  y = []\n",
        "  img_folder=r'/content/'\n",
        "  for file in os.listdir(os.path.join(img_folder, dir1)):       \n",
        "    image_path1= os.path.join(img_folder, dir1,  file)\n",
        "    x.append(preprocessing(image_path1))\n",
        "    y.append(1)\n",
        "  for file in os.listdir(os.path.join(img_folder, dir2)):\n",
        "    image_path2=os.path.join(img_folder, dir2,  file)\n",
        "    x.append(preprocessing(image_path2))\n",
        "    y.append(0)\n",
        "  x=np.array(x)\n",
        "  x=x.reshape(len(y),224,224,3)\n",
        "  y=np.array(y)\n",
        "  randomize = np.arange(len(x))\n",
        "  np.random.shuffle(randomize)\n",
        "  x = x[randomize]\n",
        "  y = y[randomize]\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "mb5OHPFTgT8n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part B**"
      ],
      "metadata": {
        "id": "lDkQqbmD7fm5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hziszgjPnoRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516f78ee-2426-4b03-9187-7ea864fb298a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0.h5\n",
            "21834768/21834768 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "effnetB0 = keras.applications.EfficientNetB0(weights='imagenet', include_top=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "addr=os.path.join(r'/content/','chair.jpg')\n",
        "img = preprocessing(addr)\n",
        "prediction(img,effnetB0,condition_check=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIKpcHUHqYks",
        "outputId": "13a3141b-b159-4643-f13f-f7804116490a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n",
            "Detected Object : rocking_chair, Probability: 24.9%\n",
            "Detected Object : barrow, Probability: 7.75%\n",
            "Detected Object : swing, Probability: 3.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part C**"
      ],
      "metadata": {
        "id": "248zFUnx7jHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "addr=os.path.join(r'/content/','bag.jpg')\n",
        "bag=preprocessing(addr)\n",
        "prediction(bag,effnetB0,condition_check=True)"
      ],
      "metadata": {
        "id": "mfDb8HdB4Aed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f060409-33ac-4bcf-fbf3-68ca835215f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step\n",
            "The Network could not classify the object.\n",
            "Maybe the object does not exist in the list of the labels!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part D**"
      ],
      "metadata": {
        "id": "1MbCDlAu8kGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train=Import_data('C-train','M-train')"
      ],
      "metadata": {
        "id": "xxwKRO_y7hms"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid,y_valid=Import_data('C-valid','M-valid')"
      ],
      "metadata": {
        "id": "Xshewp2ah8xg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compile_model(x_train,y_train,x_valid,y_valid,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHmOd7xKShgm",
        "outputId": "f6779311-5168-4924-84ee-1372b6e060e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 142s 10s/step - loss: 0.6906 - accuracy: 0.8225 - val_loss: 0.6816 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 2/5\n",
            "13/13 [==============================] - 123s 9s/step - loss: 0.6843 - accuracy: 0.9700 - val_loss: 0.6766 - val_accuracy: 0.8250 - lr: 1.0000e-04\n",
            "Epoch 3/5\n",
            "13/13 [==============================] - 124s 10s/step - loss: 0.6748 - accuracy: 0.9825 - val_loss: 0.6650 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
            "Epoch 4/5\n",
            "13/13 [==============================] - 122s 9s/step - loss: 0.6609 - accuracy: 0.9950 - val_loss: 0.6442 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 5/5\n",
            "13/13 [==============================] - 125s 10s/step - loss: 0.6479 - accuracy: 0.9925 - val_loss: 0.6290 - val_accuracy: 1.0000 - lr: 1.0000e-04\n"
          ]
        }
      ]
    }
  ]
}